---
title: "Final Project: Data Science Culmination Project"
author: "Carlie Cann, Nolan Dermigny, Kevin Pickelman"
format: pdf
---

\noindent Project Proposal: Week of November 17th-21st

\noindent Project Due: Our Final Exam Time.



## Assignment Description

This is it! This is the culmination of all your work in both of the data science courses! The parameters of this project are very general because I want to give you the chance to explore your interests and be creative. Generally, your project will go through the entire data science process. The project will involve a formal written document as well as a presentation. The written document will be worth 2/3rd's of the final grade and the presentation will be worth the other 1/3rd. 


Here are the sections on how the project will be evaluated (A rubric will be released later with more specific parameters).

* Questions and Goals: The questions you wish to answer and the goals of the project. You should have multiple questions that you answer in the project. Not all of them need to be questions that require modeling to answer, but some of them need to be.
* Data Acquisition: The project describes how the data was obtained and gives substantial backround on the data. 
* Data Preprocessing: Throughout the project, the proper preprocessing techniques (variable transformations, reshaping data, etc.) are utilized.
* Exploratory Data Analysis: Proper exploratory plots and summarizes are utilized to describe the data and showcase certain interesting aspects of the data that you will explore later in the project.
* Modeling and Analysis: This is a large portion of the project! You work toward answer the questions/goals you stated at the beginning. Your project needs to include at least 3 modeling techniques we discussed in class. You will fit, tune, and compare the methods. You will discuss the results and why they make sense in context. This section can include a wide range of modeling techniques. Your proposal should be focused on describing what you want to do in this section.
* Data Product: You present your data, models, and conclusions in a professional manner. This could include an interactive data product.


Dating App Sentiment Analysis and Rating Prediction

Data Set:

This data set was aquired from Kaggle and contains various dating app ratings. Columns include:
  
  Name - the name of the person that left the review. (string)
  Review - the actual review itself. (string)
  Rating - the rating itself ranging. 1-5 (int)
  ThumbsUp - the number of thumbs up/likes on the review (int)
  Date&Time - the date and time the review was posted
  App - the app the review was left for (string)
  
Questions & Goals:

The goal of this project is to conduct sentiment analysis on the actual reviews themselves, and analyze the results. There are three main questions to ask about the finalized sentiment analysis:

  1. How well do the sentiment analysis ratings correspond with the numerical app ratings, and can we fit a model(SVM) to predict the rating based on the sentiment scores?
  
  2. What is the overarching sentiment among the different apps, Tinder, Bumble, Hinge etc., and which app has the more postive/negative sentiments?
  
  3. How well does the sentiment rating correspond to thumbs up's, if at all? Do people tend to upvote more negative or postive reviews?

## Code

```{r}
# Library necessary packages
library(dplyr)
library(tidytext)
library(ggplot2)
library(textdata)
library(vader)
library(readr)
library(cld3)
library(tidyr)
<<<<<<< HEAD
=======
# running into errors when installing/librarying tidymodels
library(tidymodels)
library(textrecipes)
library(stopwords)
library(kernlab)
>>>>>>> 7f1bf46ea7d6e8c1c110d753dd93e11a678ab08f
```

```{r}
df <- read_csv("DatingAppReviewsDataset.csv", locale = locale(encoding = "UTF-8"))

#df$Column1 <- NULL  # need this for joining the afinn_sent and df

df <- df %>%
 rename("ThumbsUp" = "#ThumbsUp")
<<<<<<< HEAD
=======

df <- df %>%
 rename("Column1" = "...1") #consistent naming
>>>>>>> 7f1bf46ea7d6e8c1c110d753dd93e11a678ab08f

# example on using AFINN --> gotta tokenize the sentences into individual words

afinn <- get_sentiments("afinn")

#AFINN_review_example <- tibble(text = df$Review[1])
#sentiment_example <- AFINN_review_example %>%
#  unnest_tokens(word, text) %>%
#  inner_join(afinn, by = "word")


# example using Vader
#vader_example <- vader_df(df$Review[1])
#View(vader_example)
# adding vader sentiment scores to original df
#vader_scores <- vader_df(df$Review[1:10])
#SentimentScore <- vader_scores$compound


#filtering out nonenglish reviews
df$language <- cld3::detect_language(df$Review)
df |> 
  filter(language == "en")

df |> 
  mutate(language = detect_language(Review)) |>
  filter(language %in% c("en", "fy", "uk"))

# changed group_by(Column1) to group_by(...1) to match my df - Kevin 12/3
afinn_sent <- df |>
  unnest_tokens(word, Review) |>
  inner_join(afinn, by = "word") |>
<<<<<<< HEAD
  group_by(...1) |>
  summarize(AF_score = mean(value))

df <- df %>%
  left_join(afinn_sent, by = "...1")
=======
  group_by(Column1) |>  #wasn't recognizing the ...1 so i changed it to Col1
  summarize(AF_score = mean(value))

df <- df %>%
  left_join(afinn_sent, by = "Column1") #wasn't recognizing the ...1 so i changed it to Col1
>>>>>>> 7f1bf46ea7d6e8c1c110d753dd93e11a678ab08f

highest_AF_scores <- df |>
  arrange(desc(AF_score)) |>
  slice(1:20) |>
  select(c(Review, App, AF_score, language))

# feel free to add to this list if need be --> replaced the word with blanks ...
# tried to replace the words with **** but for some reason not working
<<<<<<< HEAD
=======
df$Review <- iconv(df$Review, from = "UTF-8", to = "UTF-8", sub = "")
>>>>>>> 7f1bf46ea7d6e8c1c110d753dd93e11a678ab08f
words_to_remove <- c("Cock","Cocks","Bitch","Bitches", "Fuck","cock","cocks","bitch","bitches", "fuck")
pattern <- paste0("\\b(", paste(words_to_remove, collapse = "|"), ")\\b")
df$Review <- gsub(pattern, "", df$Review, ignore.case = TRUE)

lowest_AF_scores <- df |>
  arrange((AF_score)) |>
  slice(1:20) |>
  select(c(Review, App, AF_score, language))


## maybe we can gather overall/mean AF_scores for oldest v. newest reviews - Kevin 12/3

oldest_reviews <- df |>
  arrange(`Date&Time`) |>
  slice(1:20) |>
  select(c(Review, App, `Date&Time`, AF_score, language))

newest_reviews <- df |>
  arrange(desc(`Date&Time`)) |>
  slice(1:20) |>
  select(c(Review, App, `Date&Time`, AF_score, language))


## let's see how many reviews there are by each app

number_of_reviews_by_app <- df |>
  group_by(App) |>
  summarise(review_count = n()) |>
  arrange(desc(review_count))
<<<<<<< HEAD

# tinder dominates with the most reviews, then bumble, then hinge



# lets see which app has the highest average sentiment analysis score
# first, have to drop N/A AF_scores
=======
>>>>>>> 7f1bf46ea7d6e8c1c110d753dd93e11a678ab08f

# tinder dominates with the most reviews, then bumble, then hinge

# lets see which app has the highest average sentiment analysis score
# first, have to drop N/A AF_scores


num_of_reviews_by_app_and_average_AFscore <- df|>
  drop_na(AF_score) |>
  group_by(App) |>
  summarise(average_AFscore = mean(AF_score)) |>
  arrange(desc(average_AFscore))

# sliced 100 rows of data so the model runs quicker
set.seed(96)
# sliced 100 rows of data so the model runs quicker
df_1000_rows <- df |>
  slice(1:1000) |>  #increased the num of rows
  mutate(Rating = as.factor(Rating))

# built up the recipe
recipe <- recipe(Rating ~ Review, data = df_1000_rows) %>% #changed for predicting the rating 
  step_tokenize(Review) %>%
  step_stopwords(Review) |>
  step_tfidf(Review) 

# set the model to linear regression
#model <- linear_reg() %>% set_engine("lm") this was the set up for the AFINN prediction
svm_model <- svm_rbf(mode = "classification") |>
  set_engine("kernlab")

# workflow for the recipe + model
workflow <- workflow() %>%
  add_recipe(recipe) %>%
  add_model(svm_model)

# attempted to fit
fit <- workflow %>% fit(data = df_1000_rows)

preds <- predict(fit, df_1000_rows) |>
  bind_cols(df_1000_rows |> select(Rating))

mertics <- metric_set(accuracy)
metrics(preds, truth = Rating, estimate = .pred_class)

head(preds, 10)

cm <- conf_mat(preds, truth = Rating, estimate = .pred_class)
cm

#some lovely graphs for the results

accuracy_rating <- preds |>
  group_by(Rating) |>
  summarize(accuracy = mean(.pred_class == Rating))

ggplot(accuracy_rating, aes(x = Rating, y = accuracy, fill = Rating)) +
  geom_col() +
  ylim(0, 1) +
  labs(title = "Model Accuracy by Rating", y = "Accuracy")+
  theme_minimal()

ggplot(preds, aes(x = .pred_class, fill = .pred_class)) +
  geom_bar() +
  labs(title = "Distribution of Predicted Ratings", x = "Predicted Rating", y = "Count") +
  theme_minimal()

#avg sentiment score by app
app_avgs <- df |> 
  group_by(App) |>
  summarize(
    avg_sentiment = mean(AF_score, na.rm = TRUE),
    standar_dev = sd(AF_score, na.rm = TRUE),
    avg_rating = mean(Rating, na.rm = TRUE),
    num_reviews = n()
  )

#bar chart of avg scores
ggplot(data = app_avgs, aes(x = App, y = avg_sentiment)) + geom_bar(stat = "identity")

#ratings bar chart for comparison
ggplot(data = app_avgs, aes(x = App, y = avg_rating)) + geom_bar(stat = "identity")

